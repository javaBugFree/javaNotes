
ES启动完成后，我们要学习如何操作它。
  
我们已经讲过，*操作ES* 是 **对ES发送请求**。
  
我们创建一个子项目search，在这个子项目中创建一个*专门发送各种类型请求的文件*(.http)来操作ES。
  
1. 创建search项目也要 *父子相认*。

2. 然后子项目*pom文件*如下：
```java
<?xml version="1.0" encoding="UTF-8"?>  
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">  
    <modelVersion>4.0.0</modelVersion>  
    <parent>  
        <groupId>cn.tedu</groupId>  
        <artifactId>csmall</artifactId>  
        <version>0.0.1-SNAPSHOT</version>  
        <relativePath/> <!-- lookup parent from repository -->  
    </parent>  
    <groupId>com.example</groupId>  
    <artifactId>search</artifactId>  
    <version>0.0.1-SNAPSHOT</version>  
    <name>search</name>  
    <description>search</description>  
  
    <dependencies>  
        <dependency>  
            <groupId>org.springframework.boot</groupId>  
            <artifactId>spring-boot-starter</artifactId>  
        </dependency>  
  
        <dependency>  
            <groupId>org.springframework.boot</groupId>  
            <artifactId>spring-boot-starter-test</artifactId>  
            <scope>test</scope>  
        </dependency>  
    </dependencies>  
  
</project>
```


3. 下面创建一个能够向ES发送请求的文件，这种能够 **向指定url发送请求** 的 *文件格式* 称之为 **http client** (*http 客户端*)，*文件类型* 叫 **HTTP Request文件**。
![[ES的基本使用1.png]]

我们可以起名为elasticsearch。


4. 我们先从最简单的请求开始：

`###`：三个"#"，表示 **多个请求之间的 分隔**，*也是注释*，后面 *每个请求前必须编写这个 `###`*，否则会报错。

**向es发送指令**：
```json
### 三个“#”  表示多个请求之间的分隔，也是注释，后面每个请求之前必须编写这个###，否则会报错！  
GET http://localhost:9200
```

得到的结果：
![[ES的基本使用2.png]]


5. 下面要测试ES的*分词功能*

```json
### 三个“#”  表示多个请求之间的分隔，也是注释，后面每个请求之前必须编写这个###，否则会报错！
GET http://localhost:9200

### 测试ES的分词功能，运行请求，查看分词结果。  analize：分析
POST http://localhost:9200/_analyze
Content-Type: application/json

{
  "text": "my name is hanmeimei",
  "analyzer": "standard"
}
```

- `/_analyze`：声明 **使用分析器** 进行分析。
- *Content-Type*：**请求行**：
    - `Content-Type: application/json`：声明发的内容是*JSON格式*的。
- *analyzer*：分析者(**分词器**)。
    - `standard`是 *ES默认* 的分词器。`"analyzer"： "standard"` 是可以省略的。
        - *standard* 这个分词器 **只能** 对*英文等西文字符*（**用空格分隔单词的**），进行正确分词。
            - 使用中文的话，每个字都会形成分词。

![[ES的基本使用3.png]]


## 6. 使用 **中文分词器词库插件 IK** 来 *解决中文不能正确分词* 的问题

我们解决中文不能正确分词的问题，
实际上要引入一个 *中文常见词语的词库*，分词时按照词库中的词语分词即可  

我们可以使用*免费的* **中文分词器词库插件IK** 来实现中文分词效果

在Elasticsearch的文件夹*elasticsearch-7.6.2 / plugins*中创建文件夹 *ik*，
然后将 *插件的文件* 复制到 *elasticsearch-7.6.2/plugins/ik* 中：
![[中文分词器词库插件 IK.png]]

关闭 ES的dos窗口 之后再次启动elasticsearch.bat文件运行即可。

该分词器名为：`ik_smart`

ES启动之后，将中文分词器设置完成，再运行分词
```json
{
  "text": "罗技激光鼠标",
  "analyzer": "ik_smart"
}
```
再次运行分词测试，应该看到正常的中文分词效果。
但是词库的*容量有限*，比较新的网络名词和较新出现的人名是不在词库中的。

### ik分词插件的种类

我们安装的ik实际上 *不只一个分词器*，

实际上 *除了* `ik_smart` 之外 *还有*`ik_max_word`。

例如：
```json
POST http://localhost:9200/_analyze
Content-Type: application/json

{
  "text": "北京冬季奥林匹克运动会顺利闭幕",
  "analyzer": "ik_smart"
}
```

```json
POST http://localhost:9200/_analyze
Content-Type: application/json

{
  "text": "北京冬季奥林匹克运动会顺利闭幕",
  "analyzer": "ik_max_word"
}
```

上面的两个分词器运行分词，结果会有非常明显的区别

*总结区别如下*：
**ik_smart**：
* 优点：特征是 **粗略快速** 的将文字进行分词，**占用空间小**，**查询速度快**
* 缺点：分词的 *颗粒度大*，可能跳过一些重要分词，导致查询结果不全面，*查全率低*

**ik_max_word**：
* 优点：特征是 **详细** 的文字片段进行分词，查询时 **查全率高**，不容易遗漏数据  
* 缺点：因为分词 *太过详细*，导致有一些无用分词，*占用空间较大*，*查询速度慢*
